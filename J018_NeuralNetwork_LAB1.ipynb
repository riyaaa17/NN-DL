{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZmOLGIa_af1Q"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the images to values between 0 and 1\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "# Reshape data to fit the model\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziQazGWtagfa",
        "outputId": "d0c2f6f1-0ebf-4f93-960e-b79558246976"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IByw_IEraq30",
        "outputId": "a71df0c0-2fbf-4efd-d82c-8d0be1a104e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 45s 23ms/step - loss: 0.1537 - accuracy: 0.9551 - val_loss: 0.0653 - val_accuracy: 0.9789\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 42s 22ms/step - loss: 0.0520 - accuracy: 0.9848 - val_loss: 0.0468 - val_accuracy: 0.9838\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 43s 23ms/step - loss: 0.0330 - accuracy: 0.9897 - val_loss: 0.0446 - val_accuracy: 0.9855\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0220 - accuracy: 0.9931 - val_loss: 0.0382 - val_accuracy: 0.9883\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 41s 22ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0434 - val_accuracy: 0.9872\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79e38a4e6dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(f'\\nTest accuracy: {test_acc}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oHZSmx3aujD",
        "outputId": "3d13d3bc-c83b-4bb8-87f5-f0c66da0dc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - loss: 0.0434 - accuracy: 0.9872 - 2s/epoch - 5ms/step\n",
            "\n",
            "Test accuracy: 0.9872000217437744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " 4-layer NEURAL NETWORK"
      ],
      "metadata": {
        "id": "Yyc-r0S8ace9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import scale\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.linear_model as lm\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import scale\n",
        "import sklearn.linear_model as lm\n",
        "import statsmodels.formula.api as smf\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import statsmodels.api as sm\n"
      ],
      "metadata": {
        "id": "u219zeoqoONx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps\n",
        "1. Initialization: Initialize weights and biases.\n",
        "2. Forward Propagation: Compute activations for each layer.\n",
        "3. Cost Function: Calculate the cost (or loss).\n",
        "4. Backward Propagation: Compute gradients for weights and biases.\n",
        "5. Update Weights: Adjust weights and biases using gradients."
      ],
      "metadata": {
        "id": "8bILh8UGarhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1: Initialization\n",
        "We'll start by initializing weights and biases for a 4-layer neural network. Let's assume the network architecture is 3 input neurons, two hidden layers with 4 and 3 neurons, respectively, and 1 output neuron."
      ],
      "metadata": {
        "id": "X4yg5gs-bP6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Seed for reproducibility\n",
        "np.random.seed(1)\n",
        "\n",
        "# Define the network architecture\n",
        "input_size = 3\n",
        "hidden_layer1_size = 4\n",
        "hidden_layer2_size = 3\n",
        "output_size = 1\n",
        "\n",
        "# Initialize weights and biases\n",
        "weights1 = np.random.randn(input_size, hidden_layer1_size)\n",
        "biases1 = np.zeros((1, hidden_layer1_size))\n",
        "\n",
        "weights2 = np.random.randn(hidden_layer1_size, hidden_layer2_size)\n",
        "biases2 = np.zeros((1, hidden_layer2_size))\n",
        "\n",
        "weights3 = np.random.randn(hidden_layer2_size, output_size)\n",
        "biases3 = np.zeros((1, output_size))\n",
        "\n",
        "# Activation function: Sigmoid\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n"
      ],
      "metadata": {
        "id": "y0WyQ3cjWbnA"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2: Forward Propagation"
      ],
      "metadata": {
        "id": "3LShUsPBbXRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_propagation(X):\n",
        "    # Layer 1\n",
        "    z1 = np.dot(X, weights1) + biases1\n",
        "    a1 = sigmoid(z1)\n",
        "\n",
        "    # Layer 2\n",
        "    z2 = np.dot(a1, weights2) + biases2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Output Layer\n",
        "    z3 = np.dot(a2, weights3) + biases3\n",
        "    a3 = sigmoid(z3)\n",
        "\n",
        "    return a1, a2, a3\n"
      ],
      "metadata": {
        "id": "Ip6FCyDMassl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Cost Function"
      ],
      "metadata": {
        "id": "txmhTA3HbcPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(y_true, y_pred):\n",
        "    m = y_true.shape[0]\n",
        "    cost = np.sum((y_true - y_pred) ** 2) / m\n",
        "    return cost\n"
      ],
      "metadata": {
        "id": "C1wb7Lega0NT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Backward Propagation"
      ],
      "metadata": {
        "id": "PXyUTNdlbgSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(X, y_true, a1, a2, a3):\n",
        "    global weights1, weights2, weights3, biases1, biases2, biases3\n",
        "\n",
        "    m = y_true.shape[0]\n",
        "\n",
        "    # Output layer error\n",
        "    dz3 = a3 - y_true\n",
        "    dw3 = np.dot(a2.T, dz3) / m\n",
        "    db3 = np.sum(dz3, axis=0, keepdims=True) / m\n",
        "\n",
        "    # Layer 2 error\n",
        "    dz2 = np.dot(dz3, weights3.T) * sigmoid_derivative(a2)\n",
        "    dw2 = np.dot(a1.T, dz2) / m\n",
        "    db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "\n",
        "    # Layer 1 error\n",
        "    dz1 = np.dot(dz2, weights2.T) * sigmoid_derivative(a1)\n",
        "    dw1 = np.dot(X.T, dz1) / m\n",
        "    db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "\n",
        "    return dw1, db1, dw2, db2, dw3, db3\n"
      ],
      "metadata": {
        "id": "giReV8JGa3N6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Update Weights"
      ],
      "metadata": {
        "id": "TqHluQx7bmQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(dw1, db1, dw2, db2, dw3, db3, learning_rate):\n",
        "    global weights1, weights2, weights3, biases1, biases2, biases3\n",
        "\n",
        "    weights1 -= learning_rate * dw1\n",
        "    biases1 -= learning_rate * db1\n",
        "\n",
        "    weights2 -= learning_rate * dw2\n",
        "    biases2 -= learning_rate * db2\n",
        "\n",
        "    weights3 -= learning_rate * dw3\n",
        "    biases3 -= learning_rate * db3\n"
      ],
      "metadata": {
        "id": "Fepj9zU5a44T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data\n",
        "X = np.array([[0, 0, 1],\n",
        "              [0, 1, 1],\n",
        "              [1, 0, 1],\n",
        "              [1, 1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Forward propagation\n",
        "    a1, a2, a3 = forward_propagation(X)\n",
        "\n",
        "    # Compute cost\n",
        "    cost = compute_cost(y, a3)\n",
        "\n",
        "    # Backward propagation\n",
        "    dw1, db1, dw2, db2, dw3, db3 = backward_propagation(X, y, a1, a2, a3)\n",
        "\n",
        "    # Update weights\n",
        "    update_weights(dw1, db1, dw2, db2, dw3, db3, learning_rate)\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Cost: {cost}\")\n",
        "\n",
        "# Final output after training\n",
        "a1, a2, a3 = forward_propagation(X)\n",
        "print(\"Final output:\")\n",
        "print(a3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S90rx1ba7qd",
        "outputId": "36eb9b2f-0301-4695-b12f-2880ead929fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Cost: 0.2492376745373431\n",
            "Epoch 1000, Cost: 0.2325703139496443\n",
            "Epoch 2000, Cost: 0.16630849432380088\n",
            "Epoch 3000, Cost: 0.09563982674886173\n",
            "Epoch 4000, Cost: 0.001988603223742915\n",
            "Epoch 5000, Cost: 0.0003134081520971705\n",
            "Epoch 6000, Cost: 0.000108235822191065\n",
            "Epoch 7000, Cost: 5.1870902575283084e-05\n",
            "Epoch 8000, Cost: 2.966386544515569e-05\n",
            "Epoch 9000, Cost: 1.8931653956423368e-05\n",
            "Final output:\n",
            "[[0.00167018]\n",
            " [0.99685038]\n",
            " [0.99739231]\n",
            " [0.00570573]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PUVPq1ZYa-MF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}